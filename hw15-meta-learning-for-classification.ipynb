{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 记录\n### baseline 64%\n### MAML 95.8%\n### MAML+task augmentation 96.8%","metadata":{}},{"cell_type":"code","source":"# Import modules we need\nimport glob, random\nfrom collections import OrderedDict\n\nimport numpy as np\nfrom tqdm.auto import tqdm\n\nimport torch, torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nfrom PIL import Image\nfrom IPython.display import display\n\n# Check device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"DEVICE = {device}\")\n\n# Fix random seeds\nrandom_seed = 0\nrandom.seed(random_seed)\nnp.random.seed(random_seed)\ntorch.manual_seed(random_seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:43.751818Z","iopub.execute_input":"2022-06-19T08:50:43.752277Z","iopub.status.idle":"2022-06-19T08:50:43.779292Z","shell.execute_reply.started":"2022-06-19T08:50:43.752242Z","shell.execute_reply":"2022-06-19T08:50:43.777496Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### 模型","metadata":{}},{"cell_type":"code","source":"def ConvBlock(in_ch: int, out_ch: int):\n    return nn.Sequential(\n        nn.Conv2d(in_ch, out_ch, 3, padding=1),\n        nn.BatchNorm2d(out_ch),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n    )\n\n\ndef ConvBlockFunction(x, w, b, w_bn, b_bn):\n    x = F.conv2d(x, w, b, padding=1)\n    x = F.batch_norm(\n        x, running_mean=None, running_var=None, weight=w_bn, bias=b_bn, training=True\n    )\n    x = F.relu(x)\n    x = F.max_pool2d(x, kernel_size=2, stride=2)\n    return x\n\nclass Classifier(nn.Module):\n    def __init__(self, in_ch, k_way):\n        super(Classifier, self).__init__()\n        self.conv1 = ConvBlock(in_ch, 64)\n        self.conv2 = ConvBlock(64, 64)\n        self.conv3 = ConvBlock(64, 64)\n        self.conv4 = ConvBlock(64, 64)\n        self.logits = nn.Linear(64, k_way)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = x.view(x.shape[0], -1)\n        x = self.logits(x)\n        return x\n\n    def functional_forward(self, x, params):\n        \"\"\"\n        Arguments:\n        x: input images [batch, 1, 28, 28]\n        params: model parameters,\n                i.e. weights and biases of convolution\n                     and weights and biases of\n                                   batch normalization\n                type is an OrderedDict\n\n        Arguments:\n        x: input images [batch, 1, 28, 28]\n        params: The model parameters,\n                i.e. weights and biases of convolution\n                     and batch normalization layers\n                It's an `OrderedDict`\n        \"\"\"\n        for block in [1, 2, 3, 4]:\n            x = ConvBlockFunction(\n                x,\n                params[f\"conv{block}.0.weight\"],\n                params[f\"conv{block}.0.bias\"],\n                params.get(f\"conv{block}.1.weight\"),\n                params.get(f\"conv{block}.1.bias\"),\n            )\n        x = x.view(x.shape[0], -1)\n        x = F.linear(x, params[\"logits.weight\"], params[\"logits.bias\"])\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:43.804182Z","iopub.execute_input":"2022-06-19T08:50:43.804616Z","iopub.status.idle":"2022-06-19T08:50:43.854886Z","shell.execute_reply.started":"2022-06-19T08:50:43.804583Z","shell.execute_reply":"2022-06-19T08:50:43.852877Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### 创建标签","metadata":{}},{"cell_type":"code","source":"def create_label(n_way, k_shot):\n    return torch.arange(n_way).repeat_interleave(k_shot).long()\n\n\n# Try to create labels for 5-way 2-shot setting\ncreate_label(5, 2)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:43.866521Z","iopub.execute_input":"2022-06-19T08:50:43.867764Z","iopub.status.idle":"2022-06-19T08:50:43.883597Z","shell.execute_reply.started":"2022-06-19T08:50:43.867711Z","shell.execute_reply":"2022-06-19T08:50:43.881815Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### 计算acc","metadata":{}},{"cell_type":"code","source":"def calculate_accuracy(logits, labels):\n    \"\"\"utility function for accuracy calculation\"\"\"\n    acc = np.asarray(\n        [(torch.argmax(logits, -1).cpu().numpy() == labels.cpu().numpy())]\n    ).mean()\n    return acc","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:43.933219Z","iopub.execute_input":"2022-06-19T08:50:43.934361Z","iopub.status.idle":"2022-06-19T08:50:43.947167Z","shell.execute_reply.started":"2022-06-19T08:50:43.934310Z","shell.execute_reply":"2022-06-19T08:50:43.945277Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### 创建Dataset","metadata":{}},{"cell_type":"code","source":"import random\nprint(random.randint(0,3))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:43.968670Z","iopub.execute_input":"2022-06-19T08:50:43.969131Z","iopub.status.idle":"2022-06-19T08:50:43.977338Z","shell.execute_reply.started":"2022-06-19T08:50:43.969098Z","shell.execute_reply":"2022-06-19T08:50:43.976069Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Dataset for train and val\nimport random\nclass Omniglot(Dataset):\n    def __init__(self, data_dir, k_way, q_query, task_num=None):\n        self.file_list = [\n            f for f in glob.glob(data_dir + \"**/character*\", recursive=True)\n        ]\n        # limit task number if task_num is set\n        if task_num is not None:\n            self.file_list = self.file_list[: min(len(self.file_list), task_num)]\n            \n        # 不变\n        self.transform1 = transforms.Compose([transforms.ToTensor()])\n        # 水平翻转\n        self.transform2 = transforms.Compose([transforms.RandomHorizontalFlip(p=1),\n                                             transforms.ToTensor()])\n        # 垂直翻转\n        self.transform3 = transforms.Compose([transforms.RandomVerticalFlip(p=1),\n                                             transforms.ToTensor()])\n        # 全翻\n        self.transform4 = transforms.Compose([transforms.RandomHorizontalFlip(p=1),\n                                             transforms.RandomVerticalFlip(p=1),\n                                             transforms.ToTensor()])\n        \n        self.Trans = [self.transform1, self.transform2, self.transform3, self.transform4]\n        self.n = k_way + q_query\n\n    def __getitem__(self, idx):\n        sample = np.arange(20)  # 每个类别有20张图,从里头抽self.n个当一个batch\n\n        # For random sampling the characters we want.\n        np.random.shuffle(sample) # 随机抽图片后缀\n        img_path = self.file_list[idx]  # idx为类别下标\n        img_list = [f for f in glob.glob(img_path + \"**/*.png\", recursive=True)]\n        img_list.sort()\n        \n        cur_trans = self.Trans[random.randint(0,3)]\n        imgs = [cur_trans(Image.open(img_file)) for img_file in img_list]\n        # `k_way + q_query` examples for each character\n        imgs = torch.stack(imgs)[sample[: self.n]]\n        return imgs\n\n    def __len__(self):\n        return len(self.file_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.013971Z","iopub.execute_input":"2022-06-19T08:50:44.014446Z","iopub.status.idle":"2022-06-19T08:50:44.043349Z","shell.execute_reply.started":"2022-06-19T08:50:44.014413Z","shell.execute_reply":"2022-06-19T08:50:44.041784Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Transfer Learning","metadata":{}},{"cell_type":"code","source":"def BaseSolver(\n    model,\n    optimizer,\n    x,\n    n_way,\n    k_shot,\n    q_query,\n    loss_fn,\n    inner_train_step=1,\n    inner_lr=0.4,\n    train=True,\n    return_labels=False,\n):\n    criterion, task_loss, task_acc = loss_fn, [], []\n    labels = []\n\n    for meta_batch in x:\n        # Get data\n        support_set = meta_batch[: n_way * k_shot]\n        query_set = meta_batch[n_way * k_shot :]\n\n        if train:\n            \"\"\" training loop \"\"\"\n            # Use the support set to calculate loss\n            labels = create_label(n_way, k_shot).to(device)\n            logits = model.forward(support_set)\n            loss = criterion(logits, labels)\n\n            task_loss.append(loss)\n            task_acc.append(calculate_accuracy(logits, labels))\n        else:\n            \"\"\" validation / testing loop \"\"\"\n            # First update model with support set images for `inner_train_step` steps\n            fast_weights = OrderedDict(model.named_parameters())\n\n\n            for inner_step in range(inner_train_step):\n                # Simply training\n                train_label = create_label(n_way, k_shot).to(device)\n                logits = model.functional_forward(support_set, fast_weights)\n                loss = criterion(logits, train_label)\n\n                grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n                # Perform SGD\n                fast_weights = OrderedDict(\n                    (name, param - inner_lr * grad)\n                    for ((name, param), grad) in zip(fast_weights.items(), grads)\n                )\n\n            if not return_labels:\n                \"\"\" validation \"\"\"\n                val_label = create_label(n_way, q_query).to(device)\n\n                logits = model.functional_forward(query_set, fast_weights)\n                loss = criterion(logits, val_label)\n                task_loss.append(loss)\n                task_acc.append(calculate_accuracy(logits, val_label))\n            else:\n                \"\"\" testing \"\"\"\n                logits = model.functional_forward(query_set, fast_weights)\n                labels.extend(torch.argmax(logits, -1).cpu().numpy())\n\n    if return_labels:\n        return labels\n\n    batch_loss = torch.stack(task_loss).mean()\n    task_acc = np.mean(task_acc)\n\n    if train:\n        # Update model\n        model.train()\n        optimizer.zero_grad()\n        batch_loss.backward()\n        optimizer.step()\n\n    return batch_loss, task_acc","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.069816Z","iopub.execute_input":"2022-06-19T08:50:44.070209Z","iopub.status.idle":"2022-06-19T08:50:44.093265Z","shell.execute_reply.started":"2022-06-19T08:50:44.070177Z","shell.execute_reply":"2022-06-19T08:50:44.092136Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Meta Learning","metadata":{}},{"cell_type":"code","source":"def MetaSolver(\n    model,\n    optimizer,\n    x,\n    n_way,\n    k_shot,\n    q_query,\n    loss_fn,\n    inner_train_step=1,\n    inner_lr=0.4,\n    train=True,\n    return_labels=False\n):\n    criterion, task_loss, task_acc = loss_fn, [], []\n    labels = []\n\n    for meta_batch in x:\n        # Get data\n        support_set = meta_batch[: n_way * k_shot]\n        query_set = meta_batch[n_way * k_shot :]\n\n        # Copy the params for inner loop\n        fast_weights = OrderedDict(model.named_parameters())\n\n        ### ---------- INNER TRAIN LOOP ---------- ###\n        for inner_step in range(inner_train_step):\n            # Simply training\n            train_label = create_label(n_way, k_shot).to(device)\n            logits = model.functional_forward(support_set, fast_weights)\n            loss = criterion(logits, train_label)\n            # Inner gradients update! vvvvvvvvvvvvvvvvvvvv #\n            \"\"\" Inner Loop Update \"\"\"\n            # TODO: Finish the inner loop update rule\n            grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n            # Perform SGD\n            fast_weights = OrderedDict(\n                (name, param - inner_lr * grad)\n                for ((name, param), grad) in zip(fast_weights.items(), grads)\n            )\n\n            # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ #\n\n        ### ---------- INNER VALID LOOP ---------- ###\n        if not return_labels:\n            \"\"\" training / validation \"\"\"\n            val_label = create_label(n_way, q_query).to(device)\n\n            # Collect gradients for outer loop\n            logits = model.functional_forward(query_set, fast_weights)\n            loss = criterion(logits, val_label)\n            task_loss.append(loss)\n            task_acc.append(calculate_accuracy(logits, val_label))\n        else:\n            \"\"\" testing \"\"\"\n            logits = model.functional_forward(query_set, fast_weights)\n            labels.extend(torch.argmax(logits, -1).cpu().numpy())\n\n    if return_labels:\n        return labels\n\n    # Update outer loop\n    model.train()\n    optimizer.zero_grad()\n\n    meta_batch_loss = torch.stack(task_loss).mean()\n    if train:\n        \"\"\" Outer Loop Update \"\"\"\n        # TODO: Finish the outer loop update\n        meta_batch_loss.backward()\n        optimizer.step()\n\n    task_acc = np.mean(task_acc)\n    return meta_batch_loss, task_acc","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.121195Z","iopub.execute_input":"2022-06-19T08:50:44.124237Z","iopub.status.idle":"2022-06-19T08:50:44.150285Z","shell.execute_reply.started":"2022-06-19T08:50:44.124188Z","shell.execute_reply":"2022-06-19T08:50:44.148865Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### 超参","metadata":{}},{"cell_type":"code","source":"n_way = 5\nk_shot = 1\nq_query = 1\ntrain_inner_train_step = 1\nval_inner_train_step = 3\ninner_lr = 0.4\nmeta_lr = 0.001\nmeta_batch_size = 32\nmax_epoch = 200\neval_batches = 20\ntrain_data_path = \"../input/ml2022spring-hw15/omniglot/Omniglot/images_background/\"","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.173141Z","iopub.execute_input":"2022-06-19T08:50:44.176636Z","iopub.status.idle":"2022-06-19T08:50:44.186608Z","shell.execute_reply.started":"2022-06-19T08:50:44.176585Z","shell.execute_reply":"2022-06-19T08:50:44.185230Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### DataLoader初始化","metadata":{}},{"cell_type":"code","source":"def dataloader_init(datasets, shuffle=True, num_workers=2):\n    train_set, val_set = datasets\n    train_loader = DataLoader(\n        train_set,\n        # The \"batch_size\" here is not \\\n        #    the meta batch size, but  \\\n        #    how many different        \\\n        #    characters in a task,     \\\n        #    i.e. the \"n_way\" in       \\\n        #    few-shot classification.\n        batch_size=n_way,\n        num_workers=num_workers,\n        shuffle=shuffle,\n        drop_last=True,\n    )\n    val_loader = DataLoader(\n        val_set, batch_size=n_way, num_workers=num_workers, shuffle=shuffle, drop_last=True\n    )\n\n    train_iter = iter(train_loader)\n    val_iter = iter(val_loader)\n    return (train_loader, val_loader), (train_iter, val_iter)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.221443Z","iopub.execute_input":"2022-06-19T08:50:44.221956Z","iopub.status.idle":"2022-06-19T08:50:44.231883Z","shell.execute_reply.started":"2022-06-19T08:50:44.221910Z","shell.execute_reply":"2022-06-19T08:50:44.230786Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### Model初始化","metadata":{}},{"cell_type":"code","source":"def model_init():\n    meta_model = Classifier(1, n_way).to(device)\n    optimizer = torch.optim.Adam(meta_model.parameters(), lr=meta_lr)\n    loss_fn = nn.CrossEntropyLoss().to(device)\n    return meta_model, optimizer, loss_fn","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.270646Z","iopub.execute_input":"2022-06-19T08:50:44.271180Z","iopub.status.idle":"2022-06-19T08:50:44.278969Z","shell.execute_reply.started":"2022-06-19T08:50:44.271133Z","shell.execute_reply":"2022-06-19T08:50:44.277826Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def get_meta_batch(meta_batch_size, k_shot, q_query, data_loader, iterator):\n    data = []\n    for _ in range(meta_batch_size):\n        try:\n            # a \"task_data\" tensor is representing \\\n            #     the data of a task, with size of \\\n            #     [n_way, k_shot+q_query, 1, 28, 28]\n            task_data = iterator.next()\n        except StopIteration:\n            iterator = iter(data_loader)\n            task_data = iterator.next()\n        train_data = task_data[:, :k_shot].reshape(-1, 1, 28, 28)\n        val_data = task_data[:, k_shot:].reshape(-1, 1, 28, 28)\n        task_data = torch.cat((train_data, val_data), 0)\n        data.append(task_data)\n    return torch.stack(data).to(device), iterator","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.319881Z","iopub.execute_input":"2022-06-19T08:50:44.320551Z","iopub.status.idle":"2022-06-19T08:50:44.335758Z","shell.execute_reply.started":"2022-06-19T08:50:44.320463Z","shell.execute_reply":"2022-06-19T08:50:44.334692Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### 训练","metadata":{}},{"cell_type":"code","source":"solver = 'meta' # base, meta\nmeta_model, optimizer, loss_fn = model_init()\n\n# init solver and dataset according to solver type\nif solver == 'base':\n    max_epoch = 5 # the base solver only needs 5 epochs\n    Solver = BaseSolver\n    train_set, val_set = torch.utils.data.random_split(\n        Omniglot(train_data_path, k_shot, q_query, task_num=10), [5, 5]\n    )\n    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set), shuffle=False)\n\nelif solver == 'meta':\n    Solver = MetaSolver\n    dataset = Omniglot(train_data_path, k_shot, q_query)\n    train_split = int(0.9 * len(dataset))\n    val_split = len(dataset) - train_split\n    train_set, val_set = torch.utils.data.random_split(\n        dataset, [train_split, val_split]\n    )\n    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set))\nelse:\n    raise NotImplementedError\n\n\n# main training loop\nfor epoch in range(max_epoch):\n    print(\"Epoch %d\" % (epoch + 1))\n    train_meta_loss = []\n    train_acc = []\n    # The \"step\" here is a meta-gradinet update step\n    for step in tqdm(range(max(1, len(train_loader) // meta_batch_size))):\n        x, train_iter = get_meta_batch(\n            meta_batch_size, k_shot, q_query, train_loader, train_iter\n        )\n        meta_loss, acc = Solver(\n            meta_model,\n            optimizer,\n            x,\n            n_way,\n            k_shot,\n            q_query,\n            loss_fn, \n            inner_train_step=train_inner_train_step\n        )\n        train_meta_loss.append(meta_loss.item())\n        train_acc.append(acc)\n    print(\"  Loss    : \", \"%.3f\" % (np.mean(train_meta_loss)), end=\"\\t\")\n    print(\"  Accuracy: \", \"%.3f %%\" % (np.mean(train_acc) * 100))\n\n    # See the validation accuracy after each epoch.\n    # Early stopping is welcomed to implement.\n    val_acc = []\n    for eval_step in tqdm(range(max(1, len(val_loader) // (eval_batches)))):\n        x, val_iter = get_meta_batch(\n            eval_batches, k_shot, q_query, val_loader, val_iter\n        )\n        # We update three inner steps when testing.\n        _, acc = Solver(\n            meta_model,\n            optimizer,\n            x,\n            n_way,\n            k_shot,\n            q_query,\n            loss_fn,\n            inner_train_step=val_inner_train_step,\n            train=False,\n        )\n        val_acc.append(acc)\n    print(\"  Validation accuracy: \", \"%.3f %%\" % (np.mean(val_acc) * 100))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:50:44.431627Z","iopub.execute_input":"2022-06-19T08:50:44.432326Z","iopub.status.idle":"2022-06-19T09:39:31.392636Z","shell.execute_reply.started":"2022-06-19T08:50:44.432290Z","shell.execute_reply":"2022-06-19T09:39:31.390269Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"### 测试","metadata":{}},{"cell_type":"code","source":"import os\n\n# test dataset\nclass OmniglotTest(Dataset):\n    def __init__(self, test_dir):\n        self.test_dir = test_dir\n        self.n = 5\n\n        self.transform = transforms.Compose([transforms.ToTensor()])\n\n    def __getitem__(self, idx):\n        support_files = [\n            os.path.join(self.test_dir, \"support\", f\"{idx:>04}\", f\"image_{i}.png\")\n            for i in range(self.n)\n        ]\n        query_files = [\n            os.path.join(self.test_dir, \"query\", f\"{idx:>04}\", f\"image_{i}.png\")\n            for i in range(self.n)\n        ]\n\n        support_imgs = torch.stack(\n            [self.transform(Image.open(e)) for e in support_files]\n        )\n        query_imgs = torch.stack([self.transform(Image.open(e)) for e in query_files])\n\n        return support_imgs, query_imgs\n\n    def __len__(self):\n        return len(os.listdir(os.path.join(self.test_dir, \"support\")))\n    \n    \ntest_inner_train_step = 20 # you can change this\n\ntest_batches = 20\ntest_dataset = OmniglotTest(\"../input/ml2022spring-hw15/omniglot-test/Omniglot-test\")\ntest_loader = DataLoader(test_dataset, batch_size=test_batches, shuffle=False)\n\noutput = []\nfor _, batch in enumerate(tqdm(test_loader)):\n    support_set, query_set = batch\n    x = torch.cat([support_set, query_set], dim=1)\n    x = x.to(device)\n\n    labels = Solver(\n        meta_model,\n        optimizer,\n        x,\n        n_way,\n        k_shot,\n        q_query,\n        loss_fn,\n        inner_train_step=test_inner_train_step,\n        train=False,\n        return_labels=True,\n    )\n\n    output.extend(labels)\n\n# write to csv\nwith open(\"output.csv\", \"w\") as f:\n    f.write(f\"id,class\\n\")\n    for i, label in enumerate(output):\n        f.write(f\"{i},{label}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-06-19T09:39:31.397337Z","iopub.execute_input":"2022-06-19T09:39:31.398071Z","iopub.status.idle":"2022-06-19T09:40:34.781526Z","shell.execute_reply.started":"2022-06-19T09:39:31.398020Z","shell.execute_reply":"2022-06-19T09:40:34.780152Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import time \ntime.sleep(40000)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T09:40:34.783082Z","iopub.execute_input":"2022-06-19T09:40:34.784207Z","iopub.status.idle":"2022-06-19T09:53:07.852379Z","shell.execute_reply.started":"2022-06-19T09:40:34.784161Z","shell.execute_reply":"2022-06-19T09:53:07.850994Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}