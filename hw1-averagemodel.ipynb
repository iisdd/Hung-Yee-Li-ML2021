{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 总的思路就是train很多个model然后取他们的平均值(*╹▽╹*)\n# 查看输入文件","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T17:04:56.989469Z","iopub.execute_input":"2022-04-12T17:04:56.989776Z","iopub.status.idle":"2022-04-12T17:04:56.998001Z","shell.execute_reply.started":"2022-04-12T17:04:56.989747Z","shell.execute_reply":"2022-04-12T17:04:56.996893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 导入包","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nimport torch.utils.data as data  # 制作dataset\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nimport lightgbm as lgb\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T17:04:57.011955Z","iopub.execute_input":"2022-04-12T17:04:57.012248Z","iopub.status.idle":"2022-04-12T17:04:57.018055Z","shell.execute_reply.started":"2022-04-12T17:04:57.012215Z","shell.execute_reply":"2022-04-12T17:04:57.017208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 切割数据集\n归一化效果反而会变差","metadata":{}},{"cell_type":"code","source":"def Gen_Dataset_K(ToTensor=True, K=10):      # 选用相关性最强的前K个特征\n    training_set = pd.read_csv(\"/kaggle/input/ml2021spring-hw1/covid.train.csv\")\n    test_set = pd.read_csv(\"/kaggle/input/ml2021spring-hw1/covid.test.csv\")\n    output_idx = test_set.iloc[:, 0]      # 用来输出csv的idx\n    # 分出训练&测试集\n    best_features = SelectKBest(f_regression, k=K)\n    # print(best_features)\n    x = training_set.iloc[:, 1:-1]\n    y = training_set.iloc[:, -1]\n\n    fit = best_features.fit(x, y)\n    dfscores = pd.DataFrame(fit.scores_)\n    dfcolumns = pd.DataFrame(x.columns)\n    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n    featureScores.columns = ['Specs', 'Score']  # naming the dataframe columns\n    # print('============== 前20个相关特征 ===============')\n    # print(featureScores.nlargest(20, 'Score'))  # print best K features,前14个比较显著\n    features = list(featureScores.nlargest(K, 'Score').index)\n    train_x = training_set.iloc[:, features]\n    train_y = training_set.iloc[:, -1].to_numpy()\n    test_x = test_set.iloc[:, features]\n    train_x = train_x.to_numpy()\n    test_x = test_x.to_numpy()\n    if ToTensor:  # 转成tensor给pytorch(df -> numpy -> tensor)\n        return torch.FloatTensor(train_x), torch.FloatTensor(train_y), torch.FloatTensor(test_x), output_idx\n    else:         # 直接返回numpy给sklearn训练\n        return train_x, train_y, test_x, output_idx\n\nclass MyDataset(data.Dataset):              # 自制数据集,继承Dataset,用来生成batch\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __getitem__(self, index):           # 返回的是tensor\n        x, y = self.x[index], self.y[index]\n        return x, y\n\n    def __len__(self):\n        return len(self.x)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T17:04:57.036468Z","iopub.execute_input":"2022-04-12T17:04:57.036714Z","iopub.status.idle":"2022-04-12T17:04:57.046647Z","shell.execute_reply.started":"2022-04-12T17:04:57.03669Z","shell.execute_reply":"2022-04-12T17:04:57.04552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 不同模型训练(sklearn & Pytorch)","metadata":{}},{"cell_type":"code","source":"# 自定义RMSE\nclass RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n\n    def forward(self, yhat, y):\n        return torch.sqrt(self.mse(yhat, y))\n\ndef xgb():\n    # XGBoost回归\n    model_xgb = XGBRegressor(n_estimators=3000, learning_rate=0.003, max_depth=3, random_state = 14138)\n    # train_x, train_y, test_x, output_idx = Gen_Dataset_42(ToTensor=False)\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=False, K=20)\n    model_xgb.fit(train, label)\n    pred_train_xgb = model_xgb.predict(train)  # 算一下训练集上的RMSE\n    loss_func = RMSELoss()\n    print('XGB训练集上的RMSE: ', loss_func(torch.FloatTensor(pred_train_xgb), torch.FloatTensor(label)))\n    pred_xgb = model_xgb.predict(test)\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred_xgb\n    sub.to_csv('sub_XGB.csv',index=False)\n    print('XGB预测结果输出完毕')\n    return model_xgb\n\ndef gb():\n    model = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.003, max_depth=3, random_state = 14138)\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=False, K=20)\n    model.fit(train, label)\n    pred_train = model.predict(train)  # 算一下训练集上的RMSE\n    loss_func = RMSELoss()\n    print('GB训练集上的RMSE: ', loss_func(torch.FloatTensor(pred_train), torch.FloatTensor(label)))\n    pred = model.predict(test)\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred\n    sub.to_csv('sub_GB.csv',index=False)\n    print('GB预测结果输出完毕')\n    return model\n\ndef lasso():\n    model = Lasso(alpha =0.0005, random_state=14138)\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=False, K=20)\n    model.fit(train, label)\n    pred_train = model.predict(train)  # 算一下训练集上的RMSE\n    loss_func = RMSELoss()\n    print('Lasso训练集上的RMSE: ', loss_func(torch.FloatTensor(pred_train), torch.FloatTensor(label)))\n    pred = model.predict(test)\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred\n    sub.to_csv('sub_Lasso.csv',index=False)\n    print('Lasso预测结果输出完毕')\n    return model\n\ndef E_Net():\n    model = ElasticNet(alpha =0.0005, l1_ratio=0.9, random_state=14138) # l1_ratio=1是L1正则化,=0是L2正则化\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=False, K=20)\n    model.fit(train, label)\n    pred_train = model.predict(train)  # 算一下训练集上的RMSE\n    loss_func = RMSELoss()\n    print('E_Net训练集上的RMSE: ', loss_func(torch.FloatTensor(pred_train), torch.FloatTensor(label)))\n    pred = model.predict(test)\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred\n    sub.to_csv('sub_E_Net.csv',index=False)\n    print('E_Net预测结果输出完毕')\n    return model\n\n\ndef KRR():  # 核岭回归\n    model = KernelRidge(kernel='linear')\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=False, K=20)\n    model.fit(train, label)\n    pred_train = model.predict(train)  # 算一下训练集上的RMSE\n    loss_func = RMSELoss()\n    print('KRR训练集上的RMSE: ', loss_func(torch.FloatTensor(pred_train), torch.FloatTensor(label)))\n    pred = model.predict(test)\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred\n    sub.to_csv('sub_KRR.csv',index=False)\n    print('KRR预测结果输出完毕')\n    return model\n\ndef svr():\n    model = SVR(kernel=\"linear\")\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=False, K=20)\n    model.fit(train, label)\n    pred_train = model.predict(train)  # 算一下训练集上的RMSE\n    loss_func = RMSELoss()\n    print('SVR训练集上的RMSE: ', loss_func(torch.FloatTensor(pred_train), torch.FloatTensor(label)))\n    pred = model.predict(test)\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred\n    sub.to_csv('sub_SVR.csv',index=False)\n    print('SVR预测结果输出完毕')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T17:04:57.059667Z","iopub.execute_input":"2022-04-12T17:04:57.059915Z","iopub.status.idle":"2022-04-12T17:04:57.081334Z","shell.execute_reply.started":"2022-04-12T17:04:57.059891Z","shell.execute_reply":"2022-04-12T17:04:57.080429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NN(nn.Module):\n    def __init__(self, n_features, n_hidden):\n        super(NN, self).__init__()\n        self.net = nn.Sequential(\n        nn.Linear(n_features, n_hidden),\n        nn.ReLU(),\n        nn.Linear(n_hidden, 1),\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(1)\n\ndef Nn():\n    # 神经网络部分\n    # train, label, test, output_idx = Gen_Dataset_42(ToTensor=True)\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=True, K=20)\n    [train_x, dev_x, train_y, dev_y] = train_test_split(train, label, test_size=0.08, random_state=14138)\n    train_x = train_x.cuda()\n    train_y = train_y.cuda()\n    test = test.cuda()\n    dataset = MyDataset(train_x, train_y)\n    train_loader = data.DataLoader(dataset = dataset , batch_size = 64 , shuffle = True)\n\n    n_features = 20\n    n_hidden = 64\n\n    model = NN(n_features, n_hidden).cuda()\n    epoch = 500\n    lr = 0.001\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-3)\n    loss_func = RMSELoss()\n    min_dev_rmse = 1e8\n\n    loss_train = []\n    loss_dev = []\n\n    for e in range(epoch):\n        for step, (b_x, b_y) in enumerate(train_loader):\n            output = model(b_x.cuda())\n            loss = loss_func(output, b_y.cuda())                       # cross entropy loss\n            optimizer.zero_grad()                               # clear gradients for this training step\n            loss.backward()                                     # backpropagation, compute gradients\n            optimizer.step()                                    # apply gradients\n        dev_output = model(dev_x.cuda())\n        dev_loss = loss_func(dev_output, dev_y.cuda())\n        loss_train.append(loss.cpu().detach().numpy())          # numpy是cpu-only\n        loss_dev.append(dev_loss.cpu().detach().numpy())\n        if e%20 == 0:\n            print('Epoch: ', e, '| train loss: %.4f' % loss.cpu().data.numpy(), '| dev loss: %.4f' % dev_loss.cpu().data.numpy())\n            min_dev_rmse = dev_loss\n    pred_nn = model(test).cpu().detach().numpy()\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred_nn\n    sub.to_csv('sub_NN.csv',index=False)\n    print('NN预测结果输出完毕')\n    plt.plot(loss_train)\n    plt.plot(loss_dev)\n    plt.legend(['training loss', 'test loss'])\n    plt.show()\n    return model\n# Nn()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T17:04:57.176391Z","iopub.execute_input":"2022-04-12T17:04:57.17669Z","iopub.status.idle":"2022-04-12T17:04:57.190649Z","shell.execute_reply.started":"2022-04-12T17:04:57.176663Z","shell.execute_reply":"2022-04-12T17:04:57.189445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def AverageModel():\n    model = LinearRegression()\n    train, label, test, output_idx = Gen_Dataset_K(ToTensor=False, K=20)\n    train_tensor, label_tensor, test_tensor, _ = Gen_Dataset_K(ToTensor=True, K=20)\n\n    model1 = xgb()\n    pred_train1 = model1.predict(train)                 # 模型1对训练集的预测\n    pred_test1 = model1.predict(test)                   # 模型1对测试集的预测\n\n    model2 = gb()\n    pred_train2 = model2.predict(train)\n    pred_test2 = model2.predict(test)\n\n    model3 = lasso()\n    pred_train3 = model3.predict(train)\n    pred_test3 = model3.predict(test)\n\n    model4 = E_Net()\n    pred_train4 = model4.predict(train)\n    pred_test4 = model4.predict(test)\n\n    model5 = KRR()\n    pred_train5 = model5.predict(train)\n    pred_test5 = model5.predict(test)\n\n    model6 = svr()\n    pred_train6 = model6.predict(train)\n    pred_test6 = model6.predict(test)\n\n    model7 = Nn()\n    pred_train7 = model7(train_tensor.cuda()).cpu().detach().numpy()\n    pred_test7 = model7(test_tensor.cuda()).cpu().detach().numpy()\n\n    pred = (pred_test1+pred_test2+pred_test3+pred_test4+pred_test5+pred_test6+pred_test7)/7\n    sub = pd.DataFrame()\n    sub['id'] = output_idx\n    sub['tested_positive'] = pred\n    sub.to_csv('./sub_AverageModel.csv',index=False)\n    print('AverageModel预测结果输出完毕')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T17:04:57.196255Z","iopub.execute_input":"2022-04-12T17:04:57.196506Z","iopub.status.idle":"2022-04-12T17:04:57.207261Z","shell.execute_reply.started":"2022-04-12T17:04:57.196481Z","shell.execute_reply":"2022-04-12T17:04:57.206282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AverageModel()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T17:04:57.208842Z","iopub.execute_input":"2022-04-12T17:04:57.209495Z","iopub.status.idle":"2022-04-12T17:06:48.159732Z","shell.execute_reply.started":"2022-04-12T17:04:57.209457Z","shell.execute_reply":"2022-04-12T17:06:48.158904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}