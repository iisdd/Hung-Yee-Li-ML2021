{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, ImageFolder\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n# This is for the progress bar.\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T02:19:50.062135Z","iopub.execute_input":"2022-04-27T02:19:50.062785Z","iopub.status.idle":"2022-04-27T02:19:51.763472Z","shell.execute_reply.started":"2022-04-27T02:19:50.062662Z","shell.execute_reply":"2022-04-27T02:19:51.762726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):              # 自制数据集,继承Dataset,用来生成batch\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __getitem__(self, index):           # 返回的是tensor\n        x, y = self.x[index], self.y[index]\n        return x, y\n\n    def __len__(self):\n        return len(self.x)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:19:51.764785Z","iopub.execute_input":"2022-04-27T02:19:51.76503Z","iopub.status.idle":"2022-04-27T02:19:51.771126Z","shell.execute_reply.started":"2022-04-27T02:19:51.765001Z","shell.execute_reply":"2022-04-27T02:19:51.770037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 图片预处理","metadata":{}},{"cell_type":"code","source":"def gen_loader():\n    train_tfm = transforms.Compose([\n        # Resize the image into a fixed shape (height = width = 128)\n        # transforms.Resize((128, 128)),\n        torchvision.transforms.RandomResizedCrop((224, 224), scale=(0.3, 1.0), ratio=(0.75, 1.333)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomRotation(30, expand=False, center=None),\n        transforms.ToTensor(),  # 这里自带归一化\n\n    ])\n\n    # We don't need augmentations in testing and validation.\n    # All we need here is to resize the PIL image and transform it into Tensor.\n    test_tfm = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n\n    ])\n\n\n    batch_size = 256        # 保证不超内存,越大越好\n\n    train_set = DatasetFolder(\"../input/ml2021spring-hw3/food-11/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n    valid_set = DatasetFolder(\"../input/ml2021spring-hw3/food-11/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n    unlabeled_set = DatasetFolder(\"../input/ml2021spring-hw3/food-11/training/unlabeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n    test_set = DatasetFolder(\"../input/ml2021spring-hw3/food-11/testing\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers = 8, pin_memory=True)\n    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers = 8, pin_memory=True)\n    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n    return train_loader, valid_loader, test_loader, train_set, unlabeled_set\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:19:51.772553Z","iopub.execute_input":"2022-04-27T02:19:51.773259Z","iopub.status.idle":"2022-04-27T02:19:51.785677Z","shell.execute_reply.started":"2022-04-27T02:19:51.773223Z","shell.execute_reply":"2022-04-27T02:19:51.784672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN_with_dropout(nn.Module):\n    def __init__(self):\n        super(CNN_with_dropout, self).__init__()\n        # The arguments for commonly used modules:\n        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n\n        # input image size: [3, 224, 224]\n        self.cnn_layers = nn.Sequential(\n            nn.Conv2d(3, 64, 7, 2, 3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 2, 1),  # [64, 56, 56]\n\n            nn.Conv2d(64, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n\n            nn.Conv2d(64, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),  # [128, 28, 28]\n\n            nn.Conv2d(128, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),  # [128, 14, 14]\n\n            nn.Conv2d(128, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),  # [256, 7, 7]\n\n            nn.Conv2d(256, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.AvgPool2d(7, 7, 0),  # [256]\n        )\n        self.fc_layers = nn.Sequential(\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(64, 11)\n        )\n\n    def forward(self, x):\n        # Extract features by convolutional layers.\n        x = self.cnn_layers(x)\n        # The extracted feature map must be flatten before going to fully-connected layers.\n        x = x.flatten(1)\n        # The features are transformed by fully-connected layers to obtain the final logits.\n        x = self.fc_layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:19:51.788013Z","iopub.execute_input":"2022-04-27T02:19:51.788574Z","iopub.status.idle":"2022-04-27T02:19:51.805041Z","shell.execute_reply.started":"2022-04-27T02:19:51.788524Z","shell.execute_reply":"2022-04-27T02:19:51.80404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pseudo_labels(dataset, model, threshold=0.8, batch_size = 256):\n    # This functions generates pseudo-labels of a dataset using given model.\n    # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.\n    # You are NOT allowed to use any models trained on external data for pseudo-labeling.\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # Construct a data loader.\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    # Make sure the model is in eval mode.\n    model.eval()\n    # Define softmax function.\n    softmax = nn.Softmax(dim=-1)\n\n    # Iterate over the dataset by batches.\n    data_x = torch.tensor([])\n    data_y = torch.tensor([])\n    for batch in tqdm(data_loader):\n        img, _ = batch\n        # Forward the data\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n            logits = model(img.to(device))\n\n        # Obtain the probability distributions by applying softmax on logits.\n        probs = softmax(logits)     # (n_b, 11)\n        x, y = torch.max(probs, dim=1)\n        y = y.cpu()\n        idx = x > threshold\n        data_x = torch.cat([data_x, img[idx]])\n        data_y = torch.cat([data_y, y[idx]])\n        # ---------- TODO ----------\n        # Filter the data and construct a new dataset.\n    if len(data_x) == 0:\n        return None\n    new_dataset = MyDataset(data_x, data_y)\n    # # Turn off the eval mode.\n    model.train()\n    return new_dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:19:51.806413Z","iopub.execute_input":"2022-04-27T02:19:51.806701Z","iopub.status.idle":"2022-04-27T02:19:51.822459Z","shell.execute_reply.started":"2022-04-27T02:19:51.806673Z","shell.execute_reply":"2022-04-27T02:19:51.821862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:19:51.823639Z","iopub.execute_input":"2022-04-27T02:19:51.823983Z","iopub.status.idle":"2022-04-27T02:19:51.838423Z","shell.execute_reply.started":"2022-04-27T02:19:51.823946Z","shell.execute_reply":"2022-04-27T02:19:51.83755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize a model, and put it on the device specified.\nmodel = CNN_with_dropout().to(device)\n# model = torchvision.models.resnet18()\n# model.fc = nn.Linear(in_features=512, out_features=11, bias=True)\n# model = model.to(device)\nmodel.device = device\n\nloss_func = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\nn_epochs = 200\nbatch_size = 256\nLoss_train = []\nLoss_valid = []\nAcc_train = []\nAcc_valid = []\nBest_Acc = 0        # 用来存模型\ntrain_loader, valid_loader, test_loader, train_set, unlabeled_set = gen_loader()\n# Whether to do semi-supervised learning.\ndo_semi = True\n\nfor epoch in range(n_epochs):\n    # ---------- TODO ----------\n    # In each epoch, relabel the unlabeled dataset for semi-supervised learning.\n    # Then you can combine the labeled dataset and pseudo-labeled dataset for the training.\n    if do_semi and Best_Acc > 0.5 and valid_accs[-1] > 0.5:\n        # Obtain pseudo-labels for unlabeled data using trained model.\n        pseudo_set = get_pseudo_labels(unlabeled_set, model)\n        if pseudo_set != None:\n            pseudo_loader = DataLoader(pseudo_set, batch_size=batch_size, shuffle=True)\n            # Construct a new dataset and a data loader for training.\n            # This is used in semi-supervised learning only.\n            # if pseudo_set != None:\n            #     concat_dataset = ConcatDataset([train_set, pseudo_set])\n            #     train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True,\n            #                           pin_memory=True)\n            model.train()\n            for batch in tqdm(pseudo_loader):           # unlabel标签训练\n                imgs, labels = batch\n                logits = model(imgs.to(device))\n                loss = loss_func(logits, labels.long().to(device))\n                optimizer.zero_grad()\n                loss.backward()\n                grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n                optimizer.step()\n\n    # ---------- Training ----------\n    # Make sure the model is in train mode before training.\n    model.train()\n\n    # These are used to record information in training.\n    train_loss = []\n    train_accs = []\n\n    # Iterate the training set by batches.\n    for batch in tqdm(train_loader):\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n\n        # Forward the data. (Make sure data and model are on the same device.)\n        logits = model(imgs.to(device))\n\n        # Calculate the cross-entropy loss.\n        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n        loss = loss_func(logits, labels.long().to(device))\n\n        # Gradients stored in the parameters in the previous step should be cleared out first.\n        optimizer.zero_grad()\n\n        # Compute the gradients for parameters.\n        loss.backward()\n\n        # Clip the gradient norms for stable training.\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n\n        # Update the parameters with computed gradients.\n        optimizer.step()\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n\n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss = sum(train_loss) / len(train_loss)\n    train_acc = sum(train_accs) / len(train_accs)\n\n    # Print the information.\n    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n\n    \n    \n    # ---------- Validation ----------\n    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n    model.eval()\n\n    # These are used to record information in validation.\n    valid_loss = []\n    valid_accs = []\n\n    # Iterate the validation set by batches.\n    for batch in tqdm(valid_loader):\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n\n        # We don't need gradient in validation.\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n            logits = model(imgs.to(device))\n\n        # We can still compute the loss (but not the gradient).\n        loss = loss_func(logits, labels.to(device))\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n\n    # The average loss and accuracy for entire validation set is the average of the recorded values.\n    valid_loss = sum(valid_loss) / len(valid_loss)\n    valid_acc = sum(valid_accs) / len(valid_accs)\n\n    # Print the information.\n    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n    Loss_train.append(train_loss)\n    Loss_valid.append(valid_loss)\n    Acc_train.append(train_acc)\n    Acc_valid.append(valid_acc)\n    if valid_acc > Best_Acc:\n        Best_Acc = valid_acc\n        torch.save(model, \"model(dropout).pkl\")\n\nplt.plot(Loss_train)\nplt.plot(Loss_valid)\nplt.title('Loss')\nplt.legend(['Training set', 'Valid_set'])\nplt.show()\n\nplt.plot(Acc_train)\nplt.plot(Acc_valid)\nplt.title('Accuracy')\nplt.legend(['Training set', 'Valid_set'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:19:51.840117Z","iopub.execute_input":"2022-04-27T02:19:51.840664Z","iopub.status.idle":"2022-04-27T02:21:02.976193Z","shell.execute_reply.started":"2022-04-27T02:19:51.84062Z","shell.execute_reply":"2022-04-27T02:21:02.974824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load(\"model(dropout).pkl\")\nmodel.eval()\n\n# Initialize a list to store the predictions.\npredictions = []\n\n# Iterate the testing set by batches.\nfor batch in tqdm(test_loader):\n    # A batch consists of image data and corresponding labels.\n    # But here the variable \"labels\" is useless since we do not have the ground-truth.\n    # If printing out the labels, you will find that it is always 0.\n    # This is because the wrapper (DatasetFolder) returns images and labels for each batch,\n    # so we have to create fake labels to make it work normally.\n    imgs, labels = batch\n\n    # We don't need gradient in testing, and we don't even have labels to compute loss.\n    # Using torch.no_grad() accelerates the forward process.\n    with torch.no_grad():\n        logits = model(imgs.to(device))\n\n    # Take the class with greatest logit as prediction and record it.\n    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n\n# Save predictions into the file.\nwith open(\"predict.csv\", \"w\") as f:\n\n    # The first row must be \"Id, Category\"\n    f.write(\"Id,Category\\n\")\n\n    # For the rest of the rows, each image id corresponds to a predicted class.\n    for i, pred in  enumerate(predictions):\n         f.write(f\"{i},{pred}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:21:02.977655Z","iopub.status.idle":"2022-04-27T02:21:02.97816Z","shell.execute_reply.started":"2022-04-27T02:21:02.977897Z","shell.execute_reply":"2022-04-27T02:21:02.977932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\ntime.sleep(50000)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:21:02.979776Z","iopub.status.idle":"2022-04-27T02:21:02.980384Z","shell.execute_reply.started":"2022-04-27T02:21:02.980196Z","shell.execute_reply":"2022-04-27T02:21:02.980217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}