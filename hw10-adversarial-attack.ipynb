{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 记录结果(上不了jugdeboi,在固定模型下没啥意义)\n### fgsm 59%\n### i-fgsm 1%\n### ensemble model 0%","metadata":{}},{"cell_type":"code","source":"!pip install pytorchcv","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:22:41.973627Z","iopub.execute_input":"2022-05-30T15:22:41.974094Z","iopub.status.idle":"2022-05-30T15:22:53.71039Z","shell.execute_reply.started":"2022-05-30T15:22:41.974015Z","shell.execute_reply":"2022-05-30T15:22:53.709421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 参数","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nbatch_size = 40\n\n# the mean and std are the calculated statistics from cifar_10 dataset\ncifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\ncifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n\n# convert mean and std to 3-dimensional tensors for future operations\nmean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\nstd = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n\nepsilon = 8/255/std\n# TODO: iterative fgsm attack\n# alpha (step size) can be decided by yourself\nalpha = 0.8/255/std\n\nroot = '../input/hw10-data/data' # directory for storing benign images\n# benign images: images which do not contain adversarial perturbations\n# adversarial images: images which include adversarial perturbations","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:22:53.714109Z","iopub.execute_input":"2022-05-30T15:22:53.714403Z","iopub.status.idle":"2022-05-30T15:22:58.963555Z","shell.execute_reply.started":"2022-05-30T15:22:53.714374Z","shell.execute_reply":"2022-05-30T15:22:58.96275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 创建dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport shutil\nimport numpy as np\nfrom PIL import Image\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(cifar_10_mean, cifar_10_std)\n])\n\nclass AdvDataset(Dataset):\n    def __init__(self, data_dir, transform):\n        self.images = []\n        self.labels = []\n        self.names = []\n        '''\n        data_dir\n        ├── class_dir\n        │   ├── class1.png\n        │   ├── ...\n        │   ├── class20.png\n        '''\n        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n            images = sorted(glob.glob(f'{class_dir}/*'))\n            self.images += images\n            self.labels += ([i] * len(images))\n            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n        self.transform = transform\n    def __getitem__(self, idx):\n        image = self.transform(Image.open(self.images[idx]))\n        label = self.labels[idx]\n        return image, label\n    def __getname__(self):\n        return self.names\n    def __len__(self):\n        return len(self.images)\n\nadv_set = AdvDataset(root, transform=transform)\nadv_names = adv_set.__getname__()\nadv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\nprint(f'number of images = {adv_set.__len__()}')","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:22:58.965021Z","iopub.execute_input":"2022-05-30T15:22:58.965635Z","iopub.status.idle":"2022-05-30T15:22:59.245893Z","shell.execute_reply.started":"2022-05-30T15:22:58.965598Z","shell.execute_reply":"2022-05-30T15:22:59.24506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 评估模型在正常图片上表现","metadata":{}},{"cell_type":"code","source":"# to evaluate the performance of model on benign images\ndef epoch_benign(model, loader, loss_fn):\n    model.eval()\n    train_acc, train_loss = 0.0, 0.0\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        yp = model(x)\n        loss = loss_fn(yp, y)\n        train_acc += (yp.argmax(dim=1) == y).sum().item()\n        train_loss += loss.item() * x.shape[0]\n    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:22:59.248046Z","iopub.execute_input":"2022-05-30T15:22:59.248579Z","iopub.status.idle":"2022-05-30T15:22:59.254714Z","shell.execute_reply.started":"2022-05-30T15:22:59.248539Z","shell.execute_reply":"2022-05-30T15:22:59.253938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 影像攻击算法","metadata":{}},{"cell_type":"code","source":"# perform fgsm attack\n# fgsm一步到位\ndef fgsm(model, x, y, loss_fn, epsilon=epsilon):\n    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n    loss = loss_fn(model(x_adv), y) # calculate loss\n    loss.backward() # calculate gradient\n    # fgsm: use gradient ascent on x_adv to maximize loss\n    x_adv = x_adv + epsilon * x_adv.grad.detach().sign()\n    return x_adv\n\n# TODO: perform iterative fgsm attack\n# set alpha as the step size in Global Settings section\n# alpha and num_iter can be decided by yourself\n# 迭代算法,离散化更新\ndef ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20):\n    # initialize x_adv as original benign image x\n    # write a loop of num_iter to represent the iterative times\n    # for each loop\n        # call fgsm with (epsilon = alpha) to obtain new x_adv\n        # clip new x_adv back to [x-epsilon, x+epsilon]\n    # return x_adv\n    x_adv = x.detach().clone()\n    for i in range(num_iter):\n        x_adv = fgsm(model, x_adv, y, loss_fn, epsilon=alpha)\n        x_adv = torch.clamp(x_adv, min=x-epsilon, max=x+epsilon)\n#         x_adv = torch.min(torch.max(x_adv, x-epsilon), x+epsilon)\n#         print(x-epsilon)\n    return x_adv","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:27:22.873367Z","iopub.execute_input":"2022-05-30T15:27:22.873727Z","iopub.status.idle":"2022-05-30T15:27:22.884525Z","shell.execute_reply.started":"2022-05-30T15:27:22.873697Z","shell.execute_reply":"2022-05-30T15:27:22.883625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 产生攻击完后的图片","metadata":{}},{"cell_type":"code","source":"# perform adversarial attack and generate adversarial examples\ndef gen_adv_examples(model, loader, attack, loss_fn):\n    model.eval()\n    adv_names = []\n    train_acc, train_loss = 0.0, 0.0\n    for i, (x, y) in enumerate(loader):\n        x, y = x.to(device), y.to(device)\n        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n        yp = model(x_adv)\n        loss = loss_fn(yp, y)\n        train_acc += (yp.argmax(dim=1) == y).sum().item()\n        train_loss += loss.item() * x.shape[0]\n        # store adversarial examples\n        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n\n# create directory which stores adversarial examples\ndef create_dir(data_dir, adv_dir, adv_examples, adv_names):\n    if os.path.exists(adv_dir) is not True:\n        _ = shutil.copytree(data_dir, adv_dir)\n    for example, name in zip(adv_examples, adv_names):\n        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n        im.save(os.path.join(adv_dir, name))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:26:10.322351Z","iopub.execute_input":"2022-05-30T15:26:10.322761Z","iopub.status.idle":"2022-05-30T15:26:10.333416Z","shell.execute_reply.started":"2022-05-30T15:26:10.322729Z","shell.execute_reply":"2022-05-30T15:26:10.33243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorchcv.model_provider import get_model as ptcv_get_model\n\nclass ensemble_model(nn.Module):\n    def __init__(self):\n        super(ensemble_model, self).__init__()\n        self.m1 = ptcv_get_model('resnet110_cifar10', pretrained=True).to(device)\n        self.m2 = ptcv_get_model('resnet20_cifar10', pretrained=True).to(device)\n        self.m3 = ptcv_get_model('resnet56_cifar10', pretrained=True).to(device)\n        \n    def forward(self, x):\n        x1 = self.m1(x)\n        x2 = self.m2(x)\n        x3 = self.m3(x)\n        x = torch.mean(torch.stack([x1,x2,x3], dim=-1), dim=-1)\n        return x\nmodel = ensemble_model().to(device)\n\n# resnet110_cifar10, resnet20_cifar10, resnet56_cifar10\n\nloss_fn = nn.CrossEntropyLoss()\n\nbenign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\nprint(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:26:12.617137Z","iopub.execute_input":"2022-05-30T15:26:12.617485Z","iopub.status.idle":"2022-05-30T15:26:13.41654Z","shell.execute_reply.started":"2022-05-30T15:26:12.617456Z","shell.execute_reply":"2022-05-30T15:26:13.414969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### fgsm","metadata":{}},{"cell_type":"code","source":"adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\nprint(f'fgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n\ncreate_dir(root, 'fgsm', adv_examples, adv_names)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:54:16.371822Z","iopub.execute_input":"2022-05-30T08:54:16.374395Z","iopub.status.idle":"2022-05-30T08:54:17.898302Z","shell.execute_reply.started":"2022-05-30T08:54:16.37435Z","shell.execute_reply":"2022-05-30T08:54:17.897334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### i-fgsm","metadata":{}},{"cell_type":"code","source":"# TODO: iterative fgsm attack\nadv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\nprint(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n\ncreate_dir(root, 'ifgsm', adv_examples, adv_names)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T15:27:29.065514Z","iopub.execute_input":"2022-05-30T15:27:29.066342Z","iopub.status.idle":"2022-05-30T15:27:38.60447Z","shell.execute_reply.started":"2022-05-30T15:27:29.066306Z","shell.execute_reply":"2022-05-30T15:27:38.603563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 可视化","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nclasses = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\nplt.figure(figsize=(10, 20))\ncnt = 0\nfor i, cls_name in enumerate(classes):\n    path = f'{cls_name}/{cls_name}1.png'\n    # benign image\n    cnt += 1\n    plt.subplot(len(classes), 4, cnt)\n    im = Image.open(f'../input/hw10-data/data/{path}')\n    logit = model(transform(im).unsqueeze(0).to(device))[0]\n    predict = logit.argmax(-1).item()\n    prob = logit.softmax(-1)[predict].item()\n    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n    plt.axis('off')\n    plt.imshow(np.array(im))\n    # adversarial image\n    cnt += 1\n    plt.subplot(len(classes), 4, cnt)\n    im = Image.open(f'./ifgsm/{path}')\n    logit = model(transform(im).unsqueeze(0).to(device))[0]\n    predict = logit.argmax(-1).item()\n    prob = logit.softmax(-1)[predict].item()\n    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n    plt.axis('off')\n    plt.imshow(np.array(im))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T08:58:13.52649Z","iopub.execute_input":"2022-05-30T08:58:13.526824Z","iopub.status.idle":"2022-05-30T08:58:15.158991Z","shell.execute_reply.started":"2022-05-30T08:58:13.52679Z","shell.execute_reply":"2022-05-30T08:58:15.158136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}