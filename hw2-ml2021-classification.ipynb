{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 导入包","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\n# from autosklearn.classification import AutoSklearnClassifier\nimport torch.utils.data as data\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:10:04.620778Z","iopub.execute_input":"2022-04-21T10:10:04.621104Z","iopub.status.idle":"2022-04-21T10:10:06.549597Z","shell.execute_reply.started":"2022-04-21T10:10:04.621029Z","shell.execute_reply":"2022-04-21T10:10:06.548646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_11_39(BATCH_SIZE = 1024):\n    train = np.load('../input/ml2021spring-hw2/timit_11/timit_11/train_11.npy')\n    label = np.load('../input/ml2021spring-hw2/timit_11/timit_11/train_label_11.npy')\n    test = np.load('../input/ml2021spring-hw2/timit_11/timit_11/test_11.npy')\n\n    train = train.reshape(-1, 11, 39)  # LSTM用\n    test = test.reshape(-1, 11, 39)\n\n    print('Size of training data: {}'.format(train.shape))\n    print('Size of testing data: {}'.format(test.shape))\n    # 切割数据\n    print(type(train), type(label[0]))  # numpy -> tensor, y原本是str,转成int\n    train = torch.from_numpy(train).float()\n    label = label.astype(np.int)\n    label = torch.LongTensor(label)\n    test = torch.from_numpy(test).float()\n\n    VAL_RATIO = 0.1\n\n    percent = int(train.shape[0] * (1 - VAL_RATIO))\n    train_x, train_y, dev_x, dev_y = train[:percent], label[:percent], train[percent:], label[percent:]\n    # print(train_x[0])     # 大小没有明显范围,有正有负\n    print('Size of training set: {}'.format(train_x.shape))\n    print('Size of dev set: {}'.format(dev_x.shape))\n\n    # 随机切效果不如直接切,输入是语音,如果随机切两个集就变成同分布了\n    # train_x, dev_x, train_y, dev_y = train_test_split(train, label, test_size=0.2, random_state=14138)\n\n    train_set = TIMITDataset(train_x, train_y)\n    dev_set = TIMITDataset(dev_x, dev_y)\n    test_set = TIMITDataset(test, None)\n    train_loader = data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n    dev_loader = data.DataLoader(dataset=dev_set, batch_size=BATCH_SIZE, shuffle=False)  # dev集太大了也要分批送进去\n    test_loader = data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=False)\n    return train_loader, dev_loader, test_loader, train_x, dev_x","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:10:06.551112Z","iopub.execute_input":"2022-04-21T10:10:06.551424Z","iopub.status.idle":"2022-04-21T10:10:06.562718Z","shell.execute_reply.started":"2022-04-21T10:10:06.55139Z","shell.execute_reply":"2022-04-21T10:10:06.561125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TIMITDataset(Dataset):\n    def __init__(self, sounds, labels):\n        self.sounds = sounds\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        if self.labels == None:         # 在测试集上输出\n            return self.sounds[idx]\n        return self.sounds[idx], self.labels[idx]\n\n    def __len__(self):\n        return len(self.sounds)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:10:06.564924Z","iopub.execute_input":"2022-04-21T10:10:06.565334Z","iopub.status.idle":"2022-04-21T10:10:06.574784Z","shell.execute_reply.started":"2022-04-21T10:10:06.565292Z","shell.execute_reply":"2022-04-21T10:10:06.574007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 网络结构","metadata":{}},{"cell_type":"code","source":"class FNN(nn.Module):\n    def __init__(self, n_hidden):\n        super(FNN, self).__init__()\n        self.layer1 = torch.nn.Sequential(\n            nn.BatchNorm1d(num_features=429, momentum=0.1),\n            nn.Linear(429, n_hidden),\n            nn.Dropout(0.5),\n            nn.ReLU(),\n        )\n        self.layer2 = torch.nn.Sequential(\n            nn.BatchNorm1d(num_features=n_hidden, momentum=0.1),\n            nn.Linear(n_hidden, n_hidden),\n            nn.Dropout(0.5),\n            nn.ReLU(),\n        )\n        self.layer3 = torch.nn.Sequential(\n            nn.BatchNorm1d(num_features=n_hidden, momentum=0.1),\n            nn.Linear(n_hidden, n_hidden),\n            nn.Dropout(0.5),\n            nn.ReLU(),\n        )\n        self.out = nn.Linear(n_hidden, 39)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.out(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:10:06.578647Z","iopub.execute_input":"2022-04-21T10:10:06.579039Z","iopub.status.idle":"2022-04-21T10:10:06.589666Z","shell.execute_reply.started":"2022-04-21T10:10:06.579004Z","shell.execute_reply":"2022-04-21T10:10:06.588885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, n_hidden):\n        super(LSTM, self).__init__()\n        self.layer1 = torch.nn.Sequential(\n            nn.LSTM(input_size=39, hidden_size=n_hidden, num_layers=1, batch_first=True),\n        )\n        self.layer1_1 = torch.nn.Sequential(\n            nn.Dropout(0.5),\n            nn.ReLU(),\n        )\n        self.layer2 = torch.nn.Sequential(\n            nn.LSTM(input_size=n_hidden, hidden_size=n_hidden, num_layers=1, batch_first=True),\n        )\n        self.layer2_1 = torch.nn.Sequential(\n            nn.Dropout(0.5),\n            nn.ReLU(),\n        )\n        self.layer3 = torch.nn.Sequential(\n            nn.LSTM(input_size=n_hidden, hidden_size=n_hidden, num_layers=1, batch_first=True),\n        )\n        self.layer3_1 = torch.nn.Sequential(\n            nn.Dropout(0.5),\n            nn.ReLU(),\n        )\n        self.out = nn.Linear(n_hidden, 39)\n\n\n    def forward(self, x):\n        x, _ = self.layer1(x)\n        x = self.layer1_1(x)\n        x, _ = self.layer2(x)\n        x = self.layer2_1(x)\n        x, _ = self.layer3(x)\n        x = self.layer3_1(x)\n        x = x[:, -1, :]\n        x = self.out(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:10:06.592753Z","iopub.execute_input":"2022-04-21T10:10:06.593062Z","iopub.status.idle":"2022-04-21T10:10:06.604478Z","shell.execute_reply.started":"2022-04-21T10:10:06.593038Z","shell.execute_reply":"2022-04-21T10:10:06.603761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_device():\n  return 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('硬件: ', get_device())","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:10:06.605703Z","iopub.execute_input":"2022-04-21T10:10:06.606079Z","iopub.status.idle":"2022-04-21T10:10:06.683575Z","shell.execute_reply.started":"2022-04-21T10:10:06.606044Z","shell.execute_reply":"2022-04-21T10:10:06.682769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NN训练","metadata":{}},{"cell_type":"code","source":"def Nerual_Network():\n    time_start = time.time()\n    BATCH_SIZE = 2048\n    LR = 0.001\n    EPOCH = 3\n    N_HIDDEN = 2048\n\n    train_loader, dev_loader, test_loader, train_x, dev_x = load_data_11_39(BATCH_SIZE)\n\n    model = LSTM(N_HIDDEN).cuda()\n    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n    loss_func = nn.CrossEntropyLoss()       # 自带softmax\n\n    Train_Loss = []         # 总的误差曲线\n    Dev_Loss = []\n    Train_Acc = []\n    Dev_Acc = []\n\n    for e in range(EPOCH):\n        train_loss, train_acc = 0, 0\n        dev_loss, dev_acc = 0, 0\n\n\n        model.train()       # model.train(): 启用BN和drop out, model.eval(): 沿用BN的值，并不使用drop out\n        for idx, (b_x, b_y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            output = model(b_x.cuda())\n            loss = loss_func(output, b_y.cuda())\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss\n            train_pred = torch.max(output, 1)[1].cpu()\n            train_acc += float((train_pred == b_y).sum().item())      # 预测正确的总数\n\n        # dev集验证\n        model.eval()\n        with torch.no_grad():\n            for idx, (b_x, b_y) in enumerate(dev_loader):\n                output = model(b_x.cuda())\n                loss = loss_func(output, b_y.cuda())\n\n                dev_loss += loss\n                dev_pred = torch.max(output, 1)[1].cpu()\n                dev_acc += float((dev_pred == b_y).sum().item())      # 预测正确的总数\n\n\n        print('Epoch: ', e,\n              '| train loss: %.4f' % (train_loss.cpu().data.numpy() / len(train_loader)),\n              '| train accuracy: %.4f' % (train_acc / len(train_x)),\n              '| dev loss: %.4f' % (dev_loss.cpu().data.numpy() / len(dev_loader)),\n              '| dev accuracy: %.4f' % (dev_acc / len(dev_x)),\n              )\n        Train_Loss.append(train_loss.cpu().data.numpy() / len(train_loader))\n        Train_Acc.append(train_acc / len(train_x))\n        Dev_Loss.append(dev_loss.cpu().data.numpy() / len(dev_loader))\n        Dev_Acc.append(dev_acc / len(dev_x))\n    torch.save(model, '3L_2048_LSTM.pkl')\n    plt.plot(Train_Loss)\n    plt.plot(Dev_Loss)\n    plt.title('Loss')\n    plt.legend(['Training set', 'Dev_set'])\n    plt.show()\n\n    plt.plot(Train_Acc)\n    plt.plot(Dev_Acc)\n    plt.title('Accuracy')\n    plt.legend(['Training set', 'Dev_set'])\n    plt.show()\n\n    # 输出预测结果\n    predict = []\n    model.eval()\n    with torch.no_grad():\n        for i, data in enumerate(test_loader):\n            inputs = data\n            inputs = inputs.cuda()\n            outputs = model(inputs)\n            test_pred = torch.max(outputs, 1)[1].cpu().data.numpy()\n\n            for y in test_pred:\n                predict.append(y)\n\n    res = pd.DataFrame({'Id':[i for i in range(len(predict))], 'Class':predict})\n    res.to_csv('sub_NN.csv', index=False)\n    print(\"NN模型输出完毕!\")\n    time_end = time.time()\n    print(\"NN训练总时长: %ds\" %(time_end - time_start))\n    return model\nNerual_Network()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:22:32.882333Z","iopub.execute_input":"2022-04-21T10:22:32.882653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time.sleep(50000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}